# texts_analysis

# Анализ эмоциональной окраски твитов о коронавирусе

## Описание проекта

Этот проект представляет собой анализ эмоциональной окраски (сентимента) твитов, связанных с темой коронавируса, с использованием методов машинного обучения. Основная задача - классифицировать твиты на позитивные и негативные по тональности.

## Структура проекта

- `Анализ_текста.ipynb` - основной файл с кодом анализа
- `tweets_coronavirus.csv` - исходный датасет с твитами
- `README.md` - данный файл с описанием проекта
  
## Ключевые особенности

- **Набор данных**: Используется датасет твитов о коронавирусе с предварительно размеченной тональностью (позитивной/негативной)
- **Предобработка текста**:
  - Токенизация с помощью TweetTokenizer
  - Удаление стоп-слов и пунктуации
  - Очистка от URL и специальных символов
- **Векторизация текста**: Преобразование текста в числовые признаки с помощью CountVectorizer
- **Модель машинного обучения**: Логистическая регрессия для классификации тональности
- **Визуализация**: Анализ наиболее значимых слов для каждой категории

## Результаты

Модель демонстрирует точность:
- 98.5% на обучающей выборке
- 86.7% на тестовой выборке

Проект включает визуализацию наиболее значимых слов для позитивной и негативной тональности.

## Ход работы
  1. Подготовка данных
- Загрузка датасета `tweets_coronavirus.csv`, содержащего твиты с метками тональности
- Предварительный анализ данных: просмотр структуры, проверка баланса классов
- Преобразование меток тональности в бинарный формат (0 - негативная или очень негативная, 1 - позитивная или очень позитивная)
- Заполнение пропущенных значений как `Unknown`
  2. Разделение данных
- Разделение на обучающую (70%) и тестовую (30%) выборки
- Сохранение исходных текстов и меток классов отдельно
  3. Предобработка текста
- Создание кастомного токенизатора на основе TweetTokenizer
- Приведение текста к нижнему регистру
- Удаление:
- Стоп-слов (используя список из NLTK)
- Пунктуации
- Специальных символов и одиночных букв, так как в датасете присутсвуют токены из одного символа с позицией в таблице Unicode 128 и более.
- URL-адресов, которые встречабтся редко в твитах и не несут инфорации о эмоциональной окраски текста.
- Проверка работы токенизатора на тестовой строке
  4. Векторизация текста
- Создание объекта CountVectorizer с кастомным токенизатором
- Обучение векторизатора на обучающей выборке
- Преобразование текстов в матрицу частот слов:
`train_count` - для обучающей выборки
`test_count` - для тестовой выборки
  5. Обучение модели
- Инициализация модели логистической регрессии
- Обучение модели на векторизованных данных
- Предсказание тональности для обеих выборок
  6. Оценка результатов
- Расчет accuracy на обучающей и тестовой выборках
- Визуализация наиболее значимых слов:
Топ-10 слов для позитивной тональности
Топ-10 слов для негативной тональности
![image](https://github.com/user-attachments/assets/b737b2ec-8150-4ec3-b906-585d802ce676)




## Автор

Цуркан Игорь
